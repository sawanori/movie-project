# Act-Two API 統合計画書

## 概要

Runway Act-Two API を movie-maker アプリに統合し、ストーリー生成機能の「破壊力」を最大化するための計画書。

## Act-Two API とは

- **機能**: 参照動画の動き・表情・口の動きをキャラクターに転送
- **入力**: キャラクター画像/動画 + 参照パフォーマンス動画
- **出力**: キャラクターが演技する動画
- **API提供開始**: 2025年7月21日

### サポート解像度

| タイプ | 解像度 |
|--------|--------|
| 横型 | 1280:720, 1584:672, 1104:832 |
| 縦型 | 720:1280, 832:1104 |
| 正方形 | 960:960 |

### APIコード例

```javascript
import RunwayML from '@runwayml/sdk';

const client = new RunwayML();
const task = await client.characterPerformance.create({
  model: 'act_two',
  character: { type: 'image', uri: 'キャラクター画像URL' },
  reference: { type: 'video', uri: '参照パフォーマンス動画URL' },
  ratio: '720:1280',
}).waitForTaskOutput();
```

---

## 現状の課題

### ストーリー生成の現状フロー

```
画像アップロード → AI分析 → 4シーン生成（起承転結）→ 動画化 → 結合
```

### 問題点

| 課題 | 詳細 |
|------|------|
| 演技不足 | キャラクターが「動いている」だけで「演技していない」 |
| 感情表現が弱い | AIが推測した動きのみで感情が伝わらない |
| 一貫性問題 | シーン間でキャラの顔が微妙に変わる |
| 距離感 | 視聴者が傍観者視点のまま、感情移入しにくい |

---

## 統合アイデア

### アイデア1: 感情プリセット自動適用

#### コンセプト

AIがシーン生成時に「感情」も決定し、Act-Two で感情演技を自動適用。

#### フロー

```
起（Setup）     → 😊 穏やか/日常    → プリセット: calm_neutral
承（Development）→ 😮 驚き/発見     → プリセット: surprised
転（Twist）     → 😢😡💪 クライマックス → プリセット: emotional_peak
結（Conclusion） → 😌 満足/安堵     → プリセット: satisfied_smile
```

#### 感情プリセット一覧（案）

| ID | 感情 | 用途 | 参照動画内容 |
|----|------|------|-------------|
| calm_neutral | 穏やか | 日常シーン | ゆったりとした表情、微笑み |
| surprised | 驚き | 発見・気づき | 目を見開く、口が開く |
| happy | 喜び | 良い出来事 | 笑顔、目が輝く |
| sad | 悲しみ | 別れ・喪失 | 俯く、涙 |
| angry | 怒り | 対立・葛藤 | 眉間にしわ、強い目線 |
| thinking | 考え中 | 決断前 | 視線を逸らす、顎に手 |
| satisfied | 満足 | 達成・解決 | 穏やかな笑顔、安堵 |

#### UIイメージ

```
┌─────────────────────────────────────┐
│ シーン2（承）: 発見の瞬間            │
│                                     │
│ 📝 説明: 主人公が古い手紙を見つける   │
│                                     │
│ 🎭 感情: [😮 驚き ▼]                │
│   ├ 😊 穏やか                       │
│   ├ 😮 驚き    ✓                    │
│   ├ 😢 悲しみ                       │
│   ├ 😠 怒り                         │
│   └ 🤩 喜び                         │
│                                     │
│ 📹 プレビュー: [キャラが驚く動画]    │
└─────────────────────────────────────┘
```

#### メリット

- ユーザー操作がほぼ不要（自動適用）
- カスタマイズも可能（感情を手動選択）
- 既存フローを壊さない
- 動画の質が劇的に向上

---

### アイデア2: カメラ目線モノローグ挿入

#### コンセプト

各シーンの後に、キャラがカメラ目線で心情を語るカットを追加。

#### 動画構成の変化

```
従来:
[シーン1] → [シーン2] → [シーン3] → [シーン4]

進化後:
[シーン1] → [モノローグ1] → [シーン2] → [モノローグ2] → [シーン3] → [モノローグ3] → [シーン4] → [モノローグ4]
```

#### 例

| シーン | 内容 | モノローグ |
|--------|------|-----------|
| シーン1 | 主人公が海辺を歩いている | 「あの日から、ずっとここに来たかった」 |
| シーン2 | 古い写真を見つける | 「この写真...覚えてる」 |
| シーン3 | 回想シーン | 「あの時の笑顔が忘れられない」 |
| シーン4 | 夕日を見つめる | 「また会える日を信じてる」 |

#### 実装フロー

1. AIがシーンごとに「モノローグ台詞」を生成
2. 音声合成で台詞を読み上げ（または ユーザーが録音）
3. Act-Two でキャラがカメラ目線で喋る動画を生成
4. シーン動画の間に挿入して結合

#### 破壊力ポイント

- **感情移入度UP** - キャラの内面が見える
- **映画/ドラマ的演出** - プロっぽい仕上がり
- **TikTok/Reels最適** - 語りかけ動画はエンゲージメント高い

---

### アイデア3: 「自分が主人公」モード

#### コンセプト

ユーザーの顔写真をアップロード → 全シーンで主人公として登場。

#### ユーザーフロー

```
Step 1: ストーリー画像をアップロード
        [海辺の夕日の写真]

Step 2: 主人公の顔写真をアップロード（任意）
        [自分の写真] or [スキップしてAI生成キャラ]

Step 3: ムード選択
        [感動・切ない]

Step 4: 生成開始
        → 「あなたが海辺で過去を振り返る物語」が生成される
```

#### 技術フロー

```
入力:
├── ストーリー元画像（風景など）
└── 主人公顔写真

処理:
1. AI がストーリー4シーンを生成
2. 各シーンの感情を決定
3. 感情に対応する参照動画（プリセット）を選択
4. Act-Two で主人公顔写真 + 参照動画 → 演技動画生成
5. Gen-4 で背景シーン動画を生成
6. 合成 or カット切り替えで結合

出力:
└── ユーザーが主人公の4シーン物語動画
```

#### 破壊力ポイント

- **圧倒的パーソナライズ** - 自分が映画の主人公になれる
- **SNSシェア率UP** - 自分が出てる動画は絶対シェアする
- **リピート率UP** - 違うストーリーで何度も作りたくなる
- **差別化** - 他のアプリにはない体験

---

### アイデア4: 喋るペット/キャラクター機能

#### コンセプト

ペットやキャラクター画像が喋る動画を生成（スタンドアロン機能）。

#### ユーザーフロー

```
1. ペット/キャラ画像をアップロード
2. スマホで「セリフを言う自分」を撮影（参照動画）
3. Act-Two でペットが喋る動画を生成
```

#### ユースケース

- ペットが喋るSNS動画
- アニメキャラが自分の演技で動く
- アバターでの情報発信

#### 破壊力ポイント

- **SNSバズ狙い** - 喋るペット動画は圧倒的にバズりやすい
- **簡単** - 写真1枚 + 自撮り動画だけ
- **差別化** - 他の動画生成アプリにはない機能

---

### アイデア5: 表情リミックス機能

#### コンセプト

生成済み動画の人物の表情だけ差し替え。

#### ユーザーフロー

```
1. 既存のシーン動画（人物が映っている）を選択
2. 「もっと笑顔で」「驚いた顔で」と指定
3. 参照動画を撮るか、プリセット表情から選択
4. Act-Two で表情を上書き
```

#### メリット

- **再生成不要** - 気に入らない表情だけ修正できる
- **クレジット節約** - Gen-4 を再実行せずに済む
- **微調整が可能** - ストーリーの完成度を上げられる

---

## 実装ロードマップ

### Phase 1: 感情プリセット自動適用（推奨スタート）

**工数**: 中（2-3週間）

**実装内容**:
- [ ] 感情プリセット動画の準備（7種類）
- [ ] AI ストーリー生成時に感情タグを出力
- [ ] RunwayProvider に Act-Two API メソッド追加
- [ ] シーン生成フローに Act-Two 処理を統合
- [ ] 感情選択UIの追加（シーン編集画面）

**ファイル変更**:
| ファイル | 変更内容 |
|----------|----------|
| `app/external/runway_provider.py` | `create_character_performance()` メソッド追加 |
| `app/videos/schemas.py` | `EmotionType` Enum 追加 |
| `app/tasks/storyboard_processor.py` | Act-Two 処理の統合 |
| `app/generate/storyboard/page.tsx` | 感情選択UI追加 |

### Phase 2: 感情カスタマイズUI

**工数**: 小（1週間）

**実装内容**:
- [ ] シーンごとの感情を手動選択可能に
- [ ] プレビュー機能

### Phase 3: カメラ目線モノローグ

**工数**: 大（3-4週間）

**実装内容**:
- [ ] AI モノローグ台詞生成
- [ ] 音声合成（TTS）統合
- [ ] モノローグ動画生成
- [ ] 動画結合処理の拡張
- [ ] UI追加（モノローグON/OFF、台詞編集）

### Phase 4: 自分が主人公モード

**工数**: 大（4-5週間）

**実装内容**:
- [ ] 主人公顔写真アップロード機能
- [ ] 顔写真 + 感情プリセット → 演技動画生成
- [ ] ストーリー生成プロンプトの調整（主人公視点）
- [ ] 合成/カット処理の実装

---

## 期待効果

| 指標 | 現状 | Phase 1後 | Phase 4後 |
|------|------|----------|----------|
| 動画の感情表現 | ★★☆ | ★★★★☆ | ★★★★★ |
| ユーザー体験 | ★★★ | ★★★★☆ | ★★★★★ |
| SNSシェア率 | ★★☆ | ★★★☆ | ★★★★★ |
| 競合との差別化 | ★★★ | ★★★★☆ | ★★★★★ |
| リピート率 | ★★☆ | ★★★☆ | ★★★★★ |

---

## 参考リンク

- [Runway API Documentation](https://docs.dev.runwayml.com/)
- [Creating with Act-Two – Runway Help](https://help.runwayml.com/hc/en-us/articles/42311337895827-Creating-with-Act-Two)
- [Runway Developer Portal](https://dev.runwayml.com/)

---

## 備考

- Act-Two はクレジットを消費するため、料金体系の確認が必要
- 参照動画（感情プリセット）は著作権フリーまたは自社撮影のものを使用
- 顔認識精度の観点から、キャラクター画像は正面顔が望ましい
